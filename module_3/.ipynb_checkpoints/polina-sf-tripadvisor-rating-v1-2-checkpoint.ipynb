{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "немного ссылок:\n",
    " [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков)  \n",
    " [Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать,\n",
    "                      # по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, большинство признаков у нас требует очистки и предварительной обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Prepping Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обработка NAN \n",
    "Помним что, **даже отсутствие информации может быть важным признаком!**   \n",
    "Сразу вывод - было совершено множество проб добавить такие признаки в модель, но \"выстрелил\" всего один, прочие ухудшали МАЕ либо не были существенными признаками для модели, потому в итоге в нее и не попали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Reviews\n",
    "data['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Number_of_Reviews_isNAN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обработка признаков\n",
    "Тут вынесена часть тестов, которые использовались, размышления на тему. \n",
    "\n",
    "**Все наработки перенесены в функцию preproc_data()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие признаки можно считать категориальными?\n",
    "\n",
    "City - но возможно надо заглянуть внутрь, сократить количество категорий, объединив признаки в группы\n",
    "Сразу вывод - по имеющимся данными объединять в группы не было резонно, уменьшение количества - произошло само по себе в самой модели, существенными признаками были не все города.\n",
    "\n",
    "Price Range - сейчас это строковые данные, их однозначно надо сводить к числовым, с отношением порядка, это не категриольный, а ординарный признак, выходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n",
    "# data = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для некоторых алгоритмов МЛ даже для не категориальных признаков можно применить One-Hot Encoding, и это может улучшить качество модели. Пробуйте разные подходы к кодированию признака - никто не знает заранее, что может взлететь. \n",
    "\n",
    "Были произведены пробы сделать one-hot для Price Range - по МАЕ это не улучшило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Price Range'].fillna(data['Price Range'].mode()[0], inplace=True)\n",
    "price_range_dict = {'$': 1, '$$ - $$$': 2, '$$$$': 3, None : 0}\n",
    "data['Price_Range_num'] = data['Price Range'].replace(to_replace=price_range_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Rating', hue='Price_Range_num', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видно, что распределение рейтинга в зависимости от цен в ресторане имеет схожий характер, нет аномалий для показателей рейтинга у очень дорогих ресторанов, дешевых, среднего сегмента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что для ресторанов сегмента Дешевый и Дорогой больше встречается ресторанов с оценкой 4.5\n",
    "\n",
    "для ресторанов сегмента Средний или без указания признака цены - больше встречается ресторанов с оценкой 4.\n",
    "\n",
    "Такое наблюдение позволяет предположить, что пропуски в данных Price Range можно заполнить значением Средний \n",
    "\n",
    "!!! А на практике такая замена NaN на значение \"Средний\" дает ухудшение оценки МАЕ.\n",
    "Не будем делать ее.\n",
    "Мы построим числовой (ординарный) признак \n",
    " *   1 - дешевый;\n",
    " *   2 - средний;\n",
    " *   3 - дорогой;\n",
    " *     0 - None;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Reviews'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Reviews'].nunique()) \n",
    "# уникальных отзывов 41857\n",
    "print(data['Reviews'].value_counts())\n",
    "# из них 8112 - пустых\n",
    "new_df = pd.DataFrame(data['Reviews'].value_counts().values)\n",
    "new_df[0].value_counts()\n",
    "# 30  отзывов встречается по 2 раза\n",
    "# 41826 - истинно уникальных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатываем признак следующим образом: найдем 3 наиболее часто встречаемые вида кухни.\n",
    "Создадим новые dummy-признаки с этими значениями.\n",
    "\n",
    "Сразу вывод - эксперимент не увенчался успехом, признаки не стали значимыми для модели, а какая была красивая идея, и как много на нее ушло моих сил :)\n",
    "\n",
    "если убрать из модели dummy по признаку City - а dummy по признаку Cuisine Style оставить, то МАЕ имеет хороший показатель MAE: 0.205585625\n",
    "\n",
    "но для имеющегося набора данных с City получается оценка лучше 0.19960\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Cuisine Style'] = data['Cuisine Style'].apply(lambda x: None if pd.isna(x)\n",
    "                                                else x.strip(\"[]\"))\n",
    "data['Cuisine Style'].fillna('NO INFO', inplace=True)\n",
    "\n",
    "# узнать какая кухня встречается чаще всего\n",
    "from collections import Counter\n",
    "import re\n",
    "cuis_st_counter = Counter()\n",
    "for i in data['Cuisine Style']:\n",
    "    l = re.sub('\\s\\'|\\'', '', i).split(',')\n",
    "    cuis_st_counter.update(l)\n",
    "cuis_st_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''вспомогательная функция из строки сделать список'''\n",
    "def str_to_list(string):\n",
    "        _list = [\"[\",\"]\",\"'\"]\n",
    "\n",
    "        if string != None:\n",
    "            for i in _list:\n",
    "                string = str(string).replace(i,'')\n",
    "            return string.split(', ')\n",
    "        return string\n",
    "\n",
    "    \n",
    "'''Возвращает измененный DataFrame\n",
    "Признак Cuisine Style модифицируется в 3 dummy-столбца с самыми популярными кухнями \n",
    "(Vegetarian Friendly, European, Mediterranean)'''\n",
    "def get_top_cuisine_style_dummies(dataF):\n",
    "    dataF['Cuisine Style'] = dataF['Cuisine Style'].apply(str_to_list)\n",
    "    # применяем MultiLabelBinarizer, он делает то, что мы и хотим.\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    dataF = dataF.join(pd.DataFrame(mlb.fit_transform(dataF.pop('Cuisine Style')), \n",
    "                                    index=dataF.index, columns=mlb.classes_))\n",
    "    columns_to_drop = mlb.classes_.tolist()\n",
    "    columns_to_drop.remove('Vegetarian Friendly')\n",
    "    columns_to_drop.remove('European')\n",
    "    columns_to_drop.remove('Mediterranean')\n",
    "    dataF.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    return dataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_top_cuisine_style_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant id, URL_TA, ID_TA\n",
    "исследование на тему уникальности признаков\n",
    "Сразу Вывод - не будем признак Restaurant_ID использовать для получения новых признаков и вообще не будем его использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[data['URL_TA']=='/Restaurant_Review-g187514-d7342803-Reviews-Los_Hierros-Madrid.html']\n",
    "# display(data[data.duplicated(['URL_TA', 'ID_TA'], keep=False)].sort_values(by='URL_TA'))\n",
    "# 74 записи (37 пар) где совпадают URL_TA, ID_TA\n",
    "print(len(data[data.duplicated(['URL_TA', 'ID_TA'], keep=False)]\n",
    "          .sort_values(by='URL_TA').query('sample==1')))\n",
    "print(len(data[data.duplicated(['URL_TA', 'ID_TA'], keep=False)]\n",
    "          .sort_values(by='URL_TA').query('sample==0')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Restaurant_id'].value_counts()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Есть странная закономерность: Restaurant_id совсем не уникальный id и не признак Сетевого ресторана.\n",
    " Для групп ресторанов с одним и тем же id само числовое значение id для почти всех записей имеет высоченную корреляцию со значением Ranking. Restaurant_id - тот признак, который в модель не будем включать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Restaurant_id']=='id_206']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,7)\n",
    "df_train['Ranking'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как изменится распределение в большом городе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на топ 10 городов\n",
    "for x in (df_train['City'].value_counts())[0:10].index:\n",
    "    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересчитаем абсолютное значение позиции ресторана в списке ресторанов (Ranking).\n",
    "Для каждого города найти максимальное и минимальное значение Ranking.\n",
    "Выполним minmax-пересчет признака Ranking\n",
    "\n",
    "Ranking_Absolute := (x - x_min) / (x_max - x_min)\n",
    "\n",
    "Значение 0 - соответстует лучшему ресторану, 1 - ресторану, замыкающему рейтинговый список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''подсчет абсолютного значения позиции ресторана в списке ресторанов (Ranking)\n",
    "Для каждого города найти максимальное и минимальное значение Ranking\n",
    "Выполнить minmax-пересчет признака Ranking\n",
    "Ranking_Absolute := (x - x_min) / (x_max - x_min)\n",
    "Значение 0 - соответстует лучшему ресторану, 1 - ресторану, замыкающему рейтинговый список'''\n",
    "\n",
    "def get_ranking_absolute(dataF):\n",
    "    row_list = []\n",
    "    for x in (dataF['City'].value_counts()).index:\n",
    "        dict_row = {}\n",
    "        dict_row.update({'City': x, \n",
    "                         'max_rank_in_city': dataF['Ranking'][dataF['City'] == x].max(),\n",
    "                         'min_rank_in_city': dataF['Ranking'][dataF['City'] == x].min()})\n",
    "#                          'min_rank_in_city': 1})\n",
    "\n",
    "        row_list.append(dict_row)\n",
    "\n",
    "    df_city_min_max_ranking = pd.DataFrame(row_list)\n",
    "    join_df = dataF.merge(df_city_min_max_ranking, how='left', on='City')\n",
    "    \n",
    "    rez = (join_df['Ranking']-join_df['min_rank_in_city']) / \\\n",
    "        (join_df['max_rank_in_city']-join_df['min_rank_in_city'])\n",
    "    return rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking_Absolute'] = get_ranking_absolute(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (df_train['City'].value_counts())[0:10].index:\n",
    "    df_train['Ranking_Absolute'][df_train['City'] == x].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совсем другое дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking_Absolute'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Rating', y='Ranking_Absolute', data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''возвращает DataFrame (City, max_rank_in_city) \n",
    "max_rank_in_city соответствует максимальному значению признака Ranking для города\n",
    "а именно какое максимальное место в списке ресторанов города встречалось - \n",
    "тракутем как Сколько всего ретсоранов рассматривается в городе для существующего сета данных'''\n",
    "\n",
    "def get_max_rank_in_city(dataF):\n",
    "    row_list = []\n",
    "    for x in (dataF['City'].value_counts()).index:\n",
    "        dict_row = {}\n",
    "        dict_row.update({'City': x, \n",
    "                         'max_rank_in_city': dataF['Ranking'][dataF['City'] == x].max()})\n",
    "        row_list.append(dict_row)\n",
    "\n",
    "    df_city_max_rank = pd.DataFrame(row_list)\n",
    "    return df_city_max_rank\n",
    "\n",
    "\n",
    "\n",
    "'''Подсчет относительного количества отзывов ресторана в городе\n",
    "функция возвращает значение = количество отзывов у ресторана / суммарное количество отзывов в городе'''\n",
    "\n",
    "def get_Number_of_reviews_norm(dataF):\n",
    "    reviews_in_city = dataF.groupby(by=['City'])['Number of Reviews'].sum()\n",
    "    dataF = dataF.merge(reviews_in_city, on='City', how='left', suffixes=[None, '_in_city'])\n",
    "    rez = dataF['Number of Reviews'] / dataF['Number of Reviews_in_city']\n",
    "    return rez\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим распределение целевой переменной относительно признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [корреляция признаков](https://ru.wikipedia.org/wiki/Корреляция)\n",
    "\n",
    "в этой работе было приятно использовать понятие значимости признака для модели. Новые признаки местами прицельно проверялись на корреляцию с имеющимися.\n",
    "\n",
    "Посмотрим на корреляцию еще после предобработки всех данных методом preproc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "sns.heatmap(data.drop(['sample'], axis=1).corr(),annot=True, cmap='YlGn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Теперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на всякий случай, заново подгружаем данные\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0  # помечаем где у нас тест\n",
    "df_test['Rating'] = 0  # в тесте у нас нет значения Rating, мы его должны предсказать, \n",
    "                       # по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[+] Удалили Restaurant_id, ID_TA, URL_TA\n",
    "\n",
    "Попробовали добавить признаки Х_isNAN для разных столбцов (Х)\n",
    "\n",
    "[+]Модель улучшил только Reviews_isNAN\n",
    "\n",
    "[+]Cuisine_cnt - количество типов кухонь, предлагаемых в ресторане\n",
    "\n",
    "[+]Price_Range_num - ординарный признак: 1-дешевый, 2-средний, 3-дорогой рестораны, 0-если значение None\n",
    "\n",
    "review_dates - вспомогательный, список дат отзывов из признака Reviews\n",
    "\n",
    "review_1st_date, review_2nd_date - вспомогательные - даты 1-го и 2-го отзывов\n",
    "\n",
    "[+]Days_from_last_review -  количество дней от сегодня до последнего отзыва про ресторан \n",
    "\n",
    "(max(review_1st_date, review_2nd_date))\n",
    "\n",
    "\n",
    "[+]year_of_last_review - год самого свежего отзыва\n",
    "\n",
    "[+]Review_date_delta - количество дней между двумя отзывами о ресторане\n",
    "\n",
    "[+]Number of Reviews_norm - какая часть отзывов про рестораны в городе приходится на этот ресторан\n",
    "\n",
    "[+]Ranking_Absolute - абсолютное значение позиции ресторана в списке ресторанов своего города.\n",
    "\n",
    "Значение 0 - соответстует лучшему ресторану, 1 - ресторану, замыкающему рейтинговый список\n",
    "\n",
    "[+] dummy_Cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### 1. Предобработка ############################################################## \n",
    "    # убираем не нужные для модели признаки\n",
    "    df_output.drop(['Restaurant_id','ID_TA','URL_TA'], axis = 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # ################### 2. NAN ############################################################## \n",
    "    # Далее заполняем пропуски\n",
    "    \n",
    "    # [+] Number_of_Reviews_isNAN отметим пропуски\n",
    "    # не улучшает модель, не являетс очень значимым признаком. не добавляем\n",
    "#     df_output['Number_of_Reviews_isNAN'] = pd.isna(df_output['Number of Reviews']).astype('uint8')\n",
    "    \n",
    "    df_output['Number of Reviews'].fillna(0, inplace=True)\n",
    "    \n",
    "    # изменение данных Cuisine Style: remove symbols '[' ']'\n",
    "    df_output['Cuisine Style'] = df_output['Cuisine Style'].apply(lambda x: None if pd.isna(x)\n",
    "                                                else x.strip(\"[]\"))\n",
    "    df_output['Cuisine Style'].fillna('NO INFO', inplace=True)\n",
    "\n",
    "    \n",
    "    # Price_Range_isNAN отметим присутствует ли значение\n",
    "#     df_output['Price_Range_isNAN'] = pd.isna(df_output['Price Range']).astype('uint8')\n",
    "    # заполнение пропусков Price Range самым часто встречаемым значением\n",
    "    # df['Price Range'].mode() возвращает список\n",
    "#     df_output['Price Range'].fillna(df_output['Price Range'].mode()[0], inplace=True)\n",
    "\n",
    "    df_output['Reviews_isNAN'] = pd.isna(df_output['Reviews']).astype('uint8')\n",
    "    df_output['Reviews'].fillna('[[], []]', inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ################### 4. Feature Engineering ####################################################\n",
    "    # \n",
    "    # [+] - обозначение столбцов, которые будут анализироваться на предмет \"добавить в модель\"\n",
    "    # (другие столбцы добавляются как вспомогательные, в модель не войдут)\n",
    "    \n",
    "    # [+] добавим новый столбец Cuisine_cnt - количество типов кухонь в ресторане\n",
    "    # Если тип кухни 'NO INFO' - считаем, что предлагается 1 тип\n",
    "    df_output['Cuisine_cnt'] = df_output['Cuisine Style'].apply(lambda x: 1 if x == 'NO INFO'\n",
    "                                              else len(x.split(', ')))\n",
    "    \n",
    "#     df_output = get_top_cuisine_style_dummies(df_output)\n",
    "\n",
    "    # [+] Price_Range_num числовое значение (ординарный признак) цен в ресторане\n",
    "    price_range_dict = {'$': 1, '$$ - $$$': 2, '$$$$': 3, None: 0}\n",
    "    df_output['Price_Range_num'] = df_output['Price Range'].replace(to_replace=price_range_dict)\n",
    "\n",
    "#     price_range_dict2 = {'$': 1, '$$ - $$$': 2, '$$$$': 3, None: 0}\n",
    "#     df_output['Price_Range_forDummie'] = df_output['Price Range'].replace(to_replace=price_range_dict)\n",
    "\n",
    "    \n",
    "    # блок про даты отзывов\n",
    "    # review_dates содержит список дат, когда оставили отзывы (2шт), которые отображаются на странице\n",
    "    df_output['review_dates'] = df_output['Reviews'].apply(lambda x: x.split(\n",
    "        \"], [\")[1].strip('][').replace(\"'\", '').split(', '))\n",
    "\n",
    "    # дата 1-го отзыва\n",
    "    df_output['review_1st_date'] = pd.to_datetime(\n",
    "        df_output['review_dates'].apply(lambda x: x[0]))\n",
    "    \n",
    "    # дата 2-го отзыва\n",
    "    df_output['review_2nd_date'] = pd.to_datetime(df_output['review_dates'].apply(lambda x: x[1] if len(x) == 2\n",
    "                                                                else ''))\n",
    "    \n",
    "    # [+] Days_form_last_review сколько дней прошло с последнего отзыва\n",
    "    df_output['Days_from_last_review'] = (pd.to_datetime(datetime.now()) -\n",
    "                               pd.to_datetime(df_output['review_dates'].apply(lambda x: max(x)))).apply(lambda x: x.days)\n",
    "    df_output['Days_from_last_review'].fillna(0, inplace=True)\n",
    "\n",
    "    # [+] year_of_last_review год самого свежего отзыва\n",
    "    df_output['year_of_last_review'] = pd.to_datetime(df_output['review_dates'].apply(lambda x: max(x))).apply(lambda x: x.year)\n",
    "    df_output['year_of_last_review'].fillna(0, inplace=True)\n",
    "\n",
    "    # [+] Review_date_delta -  разница в днях между 1ой и 2ой датами отзывов\n",
    "    # (? на сколько отзывы актуальны относительно друг друга ? )\n",
    "    review_delta = np.abs(df_output['review_1st_date']-df_output['review_2nd_date'])\n",
    "    df_output['Review_date_delta'] = review_delta.apply(lambda x: x.days)\n",
    "    \n",
    "    df_output['review_1st_date'].fillna(0, inplace=True)\n",
    "    df_output['review_2nd_date'].fillna(0, inplace=True)\n",
    "    df_output['Review_date_delta'].fillna(0, inplace=True)\n",
    "    \n",
    "    # [+] Ranking_Absolute - абсолютное значение позиции ресторана в списке ресторанов своего города.\n",
    "    # Значение 0 - соответстует лучшему ресторану, 1 - ресторану, замыкающему рейтинговый список\n",
    "    df_output['Ranking_Absolute'] = get_ranking_absolute(df_output)\n",
    "\n",
    "    # [+] Number of Reviews_norm - относительно количество отзывов в ресторане \n",
    "    # (относительно общего количества отзывов в городе)\n",
    "    # - какая часть всех отзывов в городе приходится на отзывы про конкретный ресторан\n",
    "    df_output['Number of Reviews_norm'] = get_Number_of_reviews_norm(df_output)\n",
    "    \n",
    "    \n",
    "    # ################### 3. Encoding ############################################################## \n",
    "    # для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n",
    "    \n",
    "    df_output = pd.get_dummies(df_output, columns=['City'], dummy_na=True)\n",
    "    \n",
    "#     df_output = pd.get_dummies(df_output, columns=['Price_Range_num'])\n",
    "    \n",
    "    \n",
    "    # ################### 5. Clean #################################################### \n",
    "    # убираем признаки которые не нужны \n",
    "    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n",
    "    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n",
    "    df_output.drop(object_columns, axis = 1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # убираем признаки, которые могут привести к переобучению модели или мало на нее влияют\n",
    "#     df_output.drop('Ranking', axis=1, inplace=True)\n",
    "#     df_output.drop('year_of_last_review', axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаем и проверяем что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = preproc_data(data)\n",
    "df_preproc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_preproc.drop(['sample'], axis=1).corr(), cmap='YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
