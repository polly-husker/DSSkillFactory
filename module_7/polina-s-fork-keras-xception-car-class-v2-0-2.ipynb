{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Классификация изображений\n\n### Основная идея этого решения: взять предобученую на ImageNet сеть Xception и дообучить под нашу задачу. \nПо ходу решения мы будем давать вам рекомендации, которые помогут улучшить качество модели. \n\n\nУдачи и Поехали!\n\nv3","metadata":{}},{"cell_type":"markdown","source":"## Выводы\n\nСразу со сложностей - столкнуалсь со сложностями, так как превышала лимит в 30 часов в неделю. Осталось для меня не выяснено как в датасете 1-model, куда я вручную переносила файлы моделей от итерации к итерации (ограничение на 8 или 9 часов работы сессии GPU) - как в датасете ходить от версии к версии.\n\n**По работе:** \n\nбыли эксперименты, где модель начиналась с базовой Efficient Net B5 (efnb5) и обучалась целиком - где-то на 80 эпoхах обучение закончилось по earlystop (patience=20) и точность модели была 81% - по времени ушло почти 8 часов\n\nбыли эксперименты, с efnb5 и xception - где базовые модели замораживались на обучении - efn давало точность выше на процентов 7-8 - тут было мало эпох, порядка 20. Было принято решение дальше экспереминтировать только с efn\n\nefn как базовая модель замораживалась, и потом было 3 этапа fine-tuning - доли размораживающихся слоев выбирались исходя из мысли - постепенно увеличивать количество обучаемых параметров модели. Для EFN подобрала сначала разморозить 1/8 часть на обучение, потом 1/4, потом все слои. \nПонравлся такой вариант тем, что он по времени показадся более эффективным. Возможно так \"сильно\" уменьшать LR от итерации fine-tuninga к слпедующей не стоит, но времени GPU пока нет, чтоб это проверить. Без GPU беспощадно долго считать (на 5 эпох уходило порядка 9-10 часов О_о)\n\nИз досадного - влетала в ходе экспериментов на превышение объемов памяти, уменьшала размер batch-ей, но время GPU было уже не вернуть, так как эксперименты ставились на ночь.\nЛюбопытно - нет ли каких-то вариантов предвидеть такие вещи, как-то просчитать - не понимаю от каких параметров и хоть примерно как (линейно, квадратично или еще как ) зависит объем памяти, клоторый нужен будет во время вычислений (в своих \"привычных\" задачах из криптографии пользуюсь таким предвариетльным анализом - а тут не знаю как)","metadata":{}},{"cell_type":"code","source":"print('ALOHA! 2')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-16T14:28:19.36914Z","iopub.execute_input":"2021-06-16T14:28:19.369482Z","iopub.status.idle":"2021-06-16T14:28:20.037198Z","shell.execute_reply.started":"2021-06-16T14:28:19.369392Z","shell.execute_reply":"2021-06-16T14:28:20.036399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, \\\n                                        EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nimport tensorflow.keras.models as Model\nfrom tensorflow.keras.applications.xception import Xception\nimport tensorflow.keras.layers as Layer\n\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-06-19T01:32:17.776035Z","iopub.execute_input":"2021-06-19T01:32:17.776489Z","iopub.status.idle":"2021-06-19T01:32:24.142956Z","shell.execute_reply.started":"2021-06-19T01:32:17.7764Z","shell.execute_reply":"2021-06-19T01:32:24.141958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Работаем с Tensorflow v2**","metadata":{}},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-18T09:08:06.657868Z","iopub.execute_input":"2021-06-18T09:08:06.658306Z","iopub.status.idle":"2021-06-18T09:08:09.452542Z","shell.execute_reply.started":"2021-06-18T09:08:06.658261Z","shell.execute_reply":"2021-06-18T09:08:09.45136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Основные настройки","metadata":{}},{"cell_type":"code","source":"# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n\n\nEPOCHS               = 75  # эпох на обучение\nBATCH_SIZE           = 16 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/sf-dl-car-classification/'\n# PATH = \"../working/car/\" # рабочая директория\nPIC_PATH = \"/kaggle/temp/\" #  директория для картинок, должна очиститься сама\nWORK_PATH = '../working/car/'\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:32:39.933152Z","iopub.execute_input":"2021-06-19T01:32:39.933564Z","iopub.status.idle":"2021-06-19T01:32:39.938546Z","shell.execute_reply.started":"2021-06-19T01:32:39.933528Z","shell.execute_reply":"2021-06-19T01:32:39.937823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir /kaggle/temp\n!ls -l /kaggle/input/","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:09.464169Z","iopub.execute_input":"2021-06-18T09:08:09.464577Z","iopub.status.idle":"2021-06-18T09:08:10.216989Z","shell.execute_reply.started":"2021-06-18T09:08:09.464535Z","shell.execute_reply":"2021-06-18T09:08:10.215532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устаналиваем конкретное значение random seed для воспроизводимости\nos.makedirs(WORK_PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-18T09:08:10.221014Z","iopub.execute_input":"2021-06-18T09:08:10.221411Z","iopub.status.idle":"2021-06-18T09:08:10.226966Z","shell.execute_reply.started":"2021-06-18T09:08:10.221369Z","shell.execute_reply":"2021-06-18T09:08:10.225842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA / Анализ данных","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:10.228627Z","iopub.execute_input":"2021-06-18T09:08:10.228961Z","iopub.status.idle":"2021-06-18T09:08:10.314205Z","shell.execute_reply.started":"2021-06-18T09:08:10.228922Z","shell.execute_reply":"2021-06-18T09:08:10.313073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:10.315256Z","iopub.execute_input":"2021-06-18T09:08:10.315526Z","iopub.status.idle":"2021-06-18T09:08:10.336121Z","shell.execute_reply.started":"2021-06-18T09:08:10.3155Z","shell.execute_reply":"2021-06-18T09:08:10.335169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.Category.value_counts()\n# распределение классов достаточно равномерное - это хорошо, классов - 10 шт","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:10.337602Z","iopub.execute_input":"2021-06-18T09:08:10.337928Z","iopub.status.idle":"2021-06-18T09:08:10.350727Z","shell.execute_reply.started":"2021-06-18T09:08:10.337898Z","shell.execute_reply":"2021-06-18T09:08:10.349908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PIC_PATH)\n        \nprint(os.listdir(PIC_PATH))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:10.352494Z","iopub.execute_input":"2021-06-18T09:08:10.352825Z","iopub.status.idle":"2021-06-18T09:08:42.955209Z","shell.execute_reply.started":"2021-06-18T09:08:10.352782Z","shell.execute_reply":"2021-06-18T09:08:42.954389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l /kaggle/temp","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:42.956268Z","iopub.execute_input":"2021-06-18T09:08:42.956701Z","iopub.status.idle":"2021-06-18T09:08:43.780126Z","shell.execute_reply.started":"2021-06-18T09:08:42.956669Z","shell.execute_reply":"2021-06-18T09:08:43.778032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PIC_PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-18T09:08:43.785321Z","iopub.execute_input":"2021-06-18T09:08:43.785874Z","iopub.status.idle":"2021-06-18T09:08:45.421368Z","shell.execute_reply.started":"2021-06-18T09:08:43.785819Z","shell.execute_reply":"2021-06-18T09:08:45.420132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать.","metadata":{}},{"cell_type":"code","source":"image = PIL.Image.open(PIC_PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:45.426265Z","iopub.execute_input":"2021-06-18T09:08:45.427013Z","iopub.status.idle":"2021-06-18T09:08:46.702845Z","shell.execute_reply.started":"2021-06-18T09:08:45.426963Z","shell.execute_reply":"2021-06-18T09:08:46.701728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Уже догадываетесь, что означают классы?\nЭто будут модели машин","metadata":{}},{"cell_type":"markdown","source":"# Подготовка данных","metadata":{}},{"cell_type":"markdown","source":"### Аугментация данных","metadata":{}},{"cell_type":"code","source":"# Вы помните, что аугментация данных важна, когда мы работаем с небольшим датасетом.\n# Это как раз наш случай.\n# Чтобы лучше понять работу параметров, попробуйте их изменить.\n# К какому результату это приведет?\n# Официальная документация: https://keras.io/preprocessing/image/\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 5,\n    zoom_range=[0.75,1.25],\n    brightness_range=[0.5, 1.5],\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\n#Рекомендация Подключите более продвинутые библиотеки аугментации изображений\n# (например: albumentations или imgaug, для них есть специальные \"обертки\" под Keras, \n# например: https://github.com/mjkvaak/ImageDataAugmentor)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:46.704614Z","iopub.execute_input":"2021-06-18T09:08:46.705182Z","iopub.status.idle":"2021-06-18T09:08:46.720235Z","shell.execute_reply.started":"2021-06-18T09:08:46.705146Z","shell.execute_reply":"2021-06-18T09:08:46.719065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Генерация данных","metadata":{}},{"cell_type":"code","source":"# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PIC_PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PIC_PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PIC_PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# Обратите внимание, что для сабмита мы используем другой источник\n# test_datagen.flow_from_dataframe. Как вы думаете, почему?\n# Потому что нам нужно дать предсказание с привязкой\n# к конкретному Id картинки из dataframe.","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:46.721854Z","iopub.execute_input":"2021-06-18T09:08:46.722608Z","iopub.status.idle":"2021-06-18T09:08:47.801947Z","shell.execute_reply.started":"2021-06-18T09:08:46.72253Z","shell.execute_reply":"2021-06-18T09:08:47.800822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на примеры картинок после аугментации","metadata":{}},{"cell_type":"code","source":"from skimage import io\n\ndef imshow(image_RGB):\n  io.imshow(image_RGB)\n  io.show()\n\nx,y = train_generator.next()\nprint('Пример картинок из train_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3, 3, i+1)\n    plt.imshow(image)\n    #plt.title('Class: '+str(y[i]))\n    #plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:47.803902Z","iopub.execute_input":"2021-06-18T09:08:47.804405Z","iopub.status.idle":"2021-06-18T09:08:50.072592Z","shell.execute_reply.started":"2021-06-18T09:08:47.80437Z","shell.execute_reply":"2021-06-18T09:08:50.071352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Построение модели","metadata":{}},{"cell_type":"markdown","source":"### Загружаем предобученную сеть  EfficientNetB5  (ver1 Xception):","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:50.074653Z","iopub.execute_input":"2021-06-18T09:08:50.075134Z","iopub.status.idle":"2021-06-18T09:08:59.646021Z","shell.execute_reply.started":"2021-06-18T09:08:50.075088Z","shell.execute_reply":"2021-06-18T09:08:59.644491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.keras as efn ","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:08:59.647794Z","iopub.execute_input":"2021-06-18T09:08:59.648096Z","iopub.status.idle":"2021-06-18T09:08:59.879602Z","shell.execute_reply.started":"2021-06-18T09:08:59.648065Z","shell.execute_reply":"2021-06-18T09:08:59.878483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model = Xception(weights='imagenet',\n#                       include_top=False,\n#                       input_shape = input_shape)\n\nbase_model = efn.EfficientNetB5(weights='imagenet', \n                                include_top=False, \n                                input_shape = input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:32:48.904075Z","iopub.execute_input":"2021-06-19T01:32:48.90459Z","iopub.status.idle":"2021-06-19T01:32:51.02053Z","shell.execute_reply.started":"2021-06-19T01:32:48.904559Z","shell.execute_reply":"2021-06-19T01:32:51.019568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-19T01:33:00.101632Z","iopub.execute_input":"2021-06-19T01:33:00.102015Z","iopub.status.idle":"2021-06-19T01:33:00.156967Z","shell.execute_reply.started":"2021-06-19T01:33:00.10198Z","shell.execute_reply":"2021-06-19T01:33:00.155521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Заморозим первый слой базовой модели Xception/Efnb5","metadata":{}},{"cell_type":"code","source":"base_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:33:13.309904Z","iopub.execute_input":"2021-06-19T01:33:13.310243Z","iopub.status.idle":"2021-06-19T01:33:13.319706Z","shell.execute_reply.started":"2021-06-19T01:33:13.310213Z","shell.execute_reply":"2021-06-19T01:33:13.318651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую \"голову\" (head)\n\nmodel=Model.Sequential()\nmodel.add(base_model)\nmodel.add(Layer.GlobalAveragePooling2D())\nmodel.add(Layer.Dense(256, \n                      activation='relu'\n                     ))\nmodel.add(Layer.BatchNormalization())\nmodel.add(Layer.Dropout(0.25))\nmodel.add(Layer.Dense(CLASS_NUM, activation='softmax'))\n\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:33:14.864844Z","iopub.execute_input":"2021-06-19T01:33:14.865224Z","iopub.status.idle":"2021-06-19T01:33:15.419139Z","shell.execute_reply.started":"2021-06-19T01:33:14.865187Z","shell.execute_reply":"2021-06-19T01:33:15.418166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\n","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-19T01:33:16.589515Z","iopub.execute_input":"2021-06-19T01:33:16.589852Z","iopub.status.idle":"2021-06-19T01:33:16.60476Z","shell.execute_reply.started":"2021-06-19T01:33:16.589823Z","shell.execute_reply":"2021-06-19T01:33:16.60387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"markdown","source":"Добавим ModelCheckpoint, чтоб сохранять прогресс обучения модели, и можно было потом подгрузить и дообучить модель.\n\nEarlyStopping - отвечает за остановку обучения модели, если метрика не улучшается на протяжении какого-то количества эпох (patience)\n\nReduceLROnPlateau - при неулучшении метрики (тут val_loss) будем изменять learning-rate на  factor","metadata":{}},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy',\n                             verbose=1, save_best_only=True, mode='max')\n\nearlystop = EarlyStopping(monitor='val_accuracy', \n                          patience=10, \n                          restore_best_weights=True,\n                          verbose=1)\n\nreduceLR = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=4,\n                              min_lr=0.0000001,\n                              verbose=1)\n\ncallbacks_list = [checkpoint, earlystop, reduceLR]\n\n# Рекомендация 1. Добавьте другие функции из https://keras.io/callbacks/\n# Рекомендация 2. Используйте разные техники управления Learning Rate\n# https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng)\n# http://teleported.in/posts/cyclic-learning-rate/ (eng)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:17:28.119401Z","iopub.execute_input":"2021-06-18T09:17:28.119776Z","iopub.status.idle":"2021-06-18T09:17:28.127996Z","shell.execute_reply.started":"2021-06-18T09:17:28.119743Z","shell.execute_reply":"2021-06-18T09:17:28.125803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers:\n    print(layer, layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:17:29.550074Z","iopub.execute_input":"2021-06-18T09:17:29.550453Z","iopub.status.idle":"2021-06-18T09:17:29.556966Z","shell.execute_reply.started":"2021-06-18T09:17:29.550417Z","shell.execute_reply":"2021-06-18T09:17:29.55599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обучаем:","metadata":{}},{"cell_type":"code","source":"# history = model.fit_generator(\n#         train_generator,\n#         steps_per_epoch = len(train_generator),\n#         validation_data = test_generator, \n#         validation_steps = len(test_generator),\n#         epochs = EPOCHS,\n#         callbacks = callbacks_list\n# )\n\n# # Рекомендация: попробуйте применить transfer learning с fine-tuning","metadata":{"execution":{"iopub.status.busy":"2021-06-17T07:33:23.216256Z","iopub.execute_input":"2021-06-17T07:33:23.216679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\n# model.save('/kaggle/working/model_last.hdf5')\n# model.load_weights('/kaggle/working/best_model.hdf5')\n# model.save('/kaggle/working/best_model_before_ft.hdf5')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:18:29.821904Z","iopub.execute_input":"2021-06-18T09:18:29.822351Z","iopub.status.idle":"2021-06-18T09:18:31.100437Z","shell.execute_reply.started":"2021-06-18T09:18:29.822312Z","shell.execute_reply":"2021-06-18T09:18:31.098664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Шаг тюнинга\n\nтут загрузим модель, которую получили на первом шаге, в ней первый слой был заморожен для обучения (был эксперимент, где EfficientnetB5 со 100 эпохами имел точность 81% точности на тесте - **todo - разобраться как откатываться к разным версиям данных в 1-model, где сохранялись файлы best_model**).\n\n(Как происхоило это все в kaggle - модель ставилась на Run&Save в фоновом режиме. Когда модель завершала работу -то в Output сохранялся файл best_model.hdf5. Его было добавлено как New Dataset в рабочую среду, и теперь он есть в Input (1-model). При изменении начальной модеди (первого шага - получения best_model) из Output надо опять \"забирать\" этот \"датасет\" кнопкой например New Version. И в рабочей среде обновляется файлик. Сейчас будем его доставать и загружать)\n\nИ да начнется fine-tuning","metadata":{}},{"cell_type":"markdown","source":"## Загружаем модель","metadata":{}},{"cell_type":"code","source":"# !ls -l /kaggle/input/1-model/","metadata":{"execution":{"iopub.status.busy":"2021-06-18T08:03:37.930868Z","iopub.execute_input":"2021-06-18T08:03:37.93127Z","iopub.status.idle":"2021-06-18T08:03:38.735448Z","shell.execute_reply.started":"2021-06-18T08:03:37.931236Z","shell.execute_reply":"2021-06-18T08:03:38.734085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # если модель уже есть - то скопируем ее из 1-model в рабочую папку\n# !cp /kaggle/input/1-model/best_model.hdf5 /kaggle/working/best_model.hdf5","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:18:50.265971Z","iopub.execute_input":"2021-06-18T09:18:50.266407Z","iopub.status.idle":"2021-06-18T09:18:54.624874Z","shell.execute_reply.started":"2021-06-18T09:18:50.266372Z","shell.execute_reply":"2021-06-18T09:18:54.623111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -q efficientnet\n\n# import efficientnet.keras as efn ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model.load_model('/kaggle/working/best_model_before_ft.hdf5')\nmodel.save('/kaggle/working/best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:18:58.290096Z","iopub.execute_input":"2021-06-18T09:18:58.290538Z","iopub.status.idle":"2021-06-18T09:19:05.862105Z","shell.execute_reply.started":"2021-06-18T09:18:58.290501Z","shell.execute_reply":"2021-06-18T09:19:05.860988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:19:07.288467Z","iopub.execute_input":"2021-06-18T09:19:07.288886Z","iopub.status.idle":"2021-06-18T09:19:07.342108Z","shell.execute_reply.started":"2021-06-18T09:19:07.288849Z","shell.execute_reply":"2021-06-18T09:19:07.340754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"в слое efn размлорозим часть параметров для обучения - последнюю 1/8 слоев - это добавит порядка (15 млн параметров в обучение для efnb5 / 7 млн параметров для xception).","metadata":{}},{"cell_type":"code","source":"# bm = model.get_layer(name='xception')\nbm = model.get_layer(name='efficientnet-b5')\n\n\n\nfine_tune_at = len(bm.layers)//8 * 7\n\nbm.trainable=True\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in bm.layers[:fine_tune_at]:\n    layer.trainable =  False","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:34:15.546766Z","iopub.execute_input":"2021-06-19T01:34:15.547221Z","iopub.status.idle":"2021-06-19T01:34:15.562943Z","shell.execute_reply.started":"2021-06-19T01:34:15.54718Z","shell.execute_reply":"2021-06-19T01:34:15.562158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fine_tune_at","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:34:17.617527Z","iopub.execute_input":"2021-06-19T01:34:17.618056Z","iopub.status.idle":"2021-06-19T01:34:17.625104Z","shell.execute_reply.started":"2021-06-19T01:34:17.618024Z","shell.execute_reply":"2021-06-19T01:34:17.624115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:34:20.162695Z","iopub.execute_input":"2021-06-19T01:34:20.163227Z","iopub.status.idle":"2021-06-19T01:34:20.181273Z","shell.execute_reply.started":"2021-06-19T01:34:20.163159Z","shell.execute_reply":"2021-06-19T01:34:20.180036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"На весь fine_tuning возьмем меньше эпох","metadata":{}},{"cell_type":"code","source":"EPOCHS               = 25  # эпох на обучение","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR=0.0001\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:19:46.673753Z","iopub.execute_input":"2021-06-18T09:19:46.674138Z","iopub.status.idle":"2021-06-18T09:19:46.702532Z","shell.execute_reply.started":"2021-06-18T09:19:46.674106Z","shell.execute_reply":"2021-06-18T09:19:46.701626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T08:05:35.637998Z","iopub.execute_input":"2021-06-18T08:05:35.638368Z","iopub.status.idle":"2021-06-18T08:05:39.960714Z","shell.execute_reply.started":"2021-06-18T08:05:35.638337Z","shell.execute_reply":"2021-06-18T08:05:39.956846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/model_ft_1.hdf5')\nmodel.load_weights('best_model.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-15T05:45:54.472708Z","iopub.execute_input":"2021-06-15T05:45:54.473047Z","iopub.status.idle":"2021-06-15T05:46:27.524201Z","shell.execute_reply.started":"2021-06-15T05:45:54.472994Z","shell.execute_reply":"2021-06-15T05:46:27.523411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В Итоге точность нашей модели составила __%. \n\n\n\nПосмотрим графики обучения:","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-15T05:46:42.438626Z","iopub.execute_input":"2021-06-15T05:46:42.438932Z","iopub.status.idle":"2021-06-15T05:46:42.769257Z","shell.execute_reply.started":"2021-06-15T05:46:42.438904Z","shell.execute_reply":"2021-06-15T05:46:42.768081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2 этап fine-tuning'a\n\nПродолжим fine-tuning","metadata":{}},{"cell_type":"code","source":"# bm = model.get_layer(name='xception')\n# fine_tune_at = len(bm.layers)//2\nbm = model.get_layer(name='efficientnet-b5')\nfine_tune_at = len(bm.layers)//4 *3\n\nbm.trainable=True\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in bm.layers[:fine_tune_at]:\n    layer.trainable =  False","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:38:15.633887Z","iopub.execute_input":"2021-06-19T01:38:15.634217Z","iopub.status.idle":"2021-06-19T01:38:15.648197Z","shell.execute_reply.started":"2021-06-19T01:38:15.634187Z","shell.execute_reply":"2021-06-19T01:38:15.647092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T01:38:17.75449Z","iopub.execute_input":"2021-06-19T01:38:17.754837Z","iopub.status.idle":"2021-06-19T01:38:17.773053Z","shell.execute_reply.started":"2021-06-19T01:38:17.754807Z","shell.execute_reply":"2021-06-19T01:38:17.772238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"разморозили четверть слоев базовой модели efn-b5, это дало порядка (20 млн параметров для efnb5 / 15 млн для xception - выбрали другой шаг fine_tune_at - чтоб добаить больше параметров) для обучения\n\nуменьшаем LR","metadata":{}},{"cell_type":"code","source":"LR=0.00001\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/model_ft_2.hdf5')\nmodel.load_weights('best_model.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В Итоге точность нашей модели составила __%. \n\n  \n\nПосмотрим графики обучения:","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3 этап","metadata":{}},{"cell_type":"markdown","source":"разморозим все слои","metadata":{}},{"cell_type":"code","source":"# bm = model.get_layer(name='xception')\nbm = model.get_layer(name='efficientnet-b5')\nfine_tune_at = 0\n\nbm.trainable=True\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in bm.layers[:fine_tune_at]:\n    layer.trainable =  False","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:30:48.580192Z","iopub.execute_input":"2021-06-18T09:30:48.580688Z","iopub.status.idle":"2021-06-18T09:30:48.613633Z","shell.execute_reply.started":"2021-06-18T09:30:48.580655Z","shell.execute_reply":"2021-06-18T09:30:48.612539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T09:30:50.196354Z","iopub.execute_input":"2021-06-18T09:30:50.196854Z","iopub.status.idle":"2021-06-18T09:30:50.264604Z","shell.execute_reply.started":"2021-06-18T09:30:50.196814Z","shell.execute_reply":"2021-06-18T09:30:50.263643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR=0.000005\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/model_ft_3.hdf5')\ntry:\n    model.load_weights('best_model.hdf5')\nexcept:\n    model = Model.load_model('/kaggle/working/best_model.hdf5')\nmodel.save('/kaggle/working/model_final.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-06-18T20:13:57.020187Z","iopub.execute_input":"2021-06-18T20:13:57.020864Z","iopub.status.idle":"2021-06-18T20:13:57.026516Z","shell.execute_reply.started":"2021-06-18T20:13:57.020752Z","shell.execute_reply":"2021-06-18T20:13:57.025766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В Итоге точность нашей модели составила __%. \n\n\n\nПосмотрим графики обучения:","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предсказание на тестовых данных","metadata":{}},{"cell_type":"code","source":"test_sub_generator.samples","metadata":{"execution":{"iopub.status.busy":"2021-06-15T05:46:53.769756Z","iopub.execute_input":"2021-06-15T05:46:53.770091Z","iopub.status.idle":"2021-06-15T05:46:53.776108Z","shell.execute_reply.started":"2021-06-15T05:46:53.770057Z","shell.execute_reply":"2021-06-15T05:46:53.77523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","metadata":{"execution":{"iopub.status.busy":"2021-06-15T05:46:56.409241Z","iopub.execute_input":"2021-06-15T05:46:56.409555Z","iopub.status.idle":"2021-06-15T05:47:37.529023Z","shell.execute_reply.started":"2021-06-15T05:46:56.409524Z","shell.execute_reply":"2021-06-15T05:47:37.528313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')\n\n# Рекомендация: попробуйте добавить Test Time Augmentation (TTA)\n# https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","metadata":{"execution":{"iopub.status.busy":"2021-06-15T05:47:58.350855Z","iopub.execute_input":"2021-06-15T05:47:58.351192Z","iopub.status.idle":"2021-06-15T05:47:58.544486Z","shell.execute_reply.started":"2021-06-15T05:47:58.351162Z","shell.execute_reply":"2021-06-15T05:47:58.543606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T05:48:20.416216Z","iopub.execute_input":"2021-06-15T05:48:20.41653Z","iopub.status.idle":"2021-06-15T05:48:20.42809Z","shell.execute_reply.started":"2021-06-15T05:48:20.416493Z","shell.execute_reply":"2021-06-15T05:48:20.427093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean PATH\n# import shutil\n# shutil.rmtree(PATH)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Интересно, к какому классу модель отнесет вот эти автомобили?","metadata":{}},{"cell_type":"markdown","source":"# Что можно сделать, чтобы улучшить результат:","metadata":{}},{"cell_type":"markdown","source":"* Примените transfer learning с fine-tuning\n* Настройте LR, optimizer, loss\n* Подберите другие переменные (размер картинки, батч и т.д.)\n* Попробуйте и другие архитектуры сетей (а не только Xception) или их ансамбли. Примеры SOTA на ImageNet  \n* \n* Добавьте Batch Normalization и поэкспериментируйте с архитектурой “головы”\n* Примените другие функции callback Keras https://keras.io/callbacks/ \n* Добавьте TTA (Test Time Augmentation)\n* Дополнительно*: Используйте разные техники управления Learning Rate (https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng) http://teleported.in/posts/cyclic-learning-rate/ (eng))\n* Дополнительно*: Добавьте более продвинутые библиотеки аугментации изображений (например, Albumentations )\n\n### Удачи в соревновании!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}